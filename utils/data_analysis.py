import pandas as pd
import numpy as np
from collections import Counter
import re

def analyze_tipo_comedor(df):
    """
    Analiza la distribuci√≥n de tipos de comedores
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos de comedores
    
    Returns:
        tuple: (tipo_counts, analysis_text) - Conteos y an√°lisis textual
    """
    if df is None or df.empty:
        return None, None
    
    # Verificar que existe la columna
    if 'TIPO DE COMEDOR' not in df.columns:
        return None, "‚ùå La columna 'TIPO DE COMEDOR' no se encontr√≥ en los datos"
    
    # Contar valores en TIPO DE COMEDOR (excluyendo valores nulos)
    tipo_counts = df['TIPO DE COMEDOR'].dropna().value_counts()
    
    if tipo_counts.empty:
        return None, "‚ö†Ô∏è No hay datos v√°lidos en la columna 'TIPO DE COMEDOR'"
    
    # Calcular porcentajes
    tipo_percentages = (tipo_counts / len(df.dropna(subset=['TIPO DE COMEDOR']))) * 100
    
    # Crear an√°lisis textual
    total_comedores = len(df.dropna(subset=['TIPO DE COMEDOR']))
    tipos_disponibles = list(tipo_counts.index)
    
    analysis_text = f"""
## üìä An√°lisis de Tipos de Comedores

**Resumen General:**
- **Total de comedores registrados:** {total_comedores:,}
- **Tipos identificados:** {len(tipos_disponibles)}
- **Registros con datos v√°lidos:** {total_comedores:,} de {len(df):,} ({(total_comedores/len(df)*100):.1f}%)

**Distribuci√≥n por tipo:**
"""
    
    for tipo, count in tipo_counts.items():
        percentage = (count / total_comedores) * 100
        analysis_text += f"\n- **{tipo}:** {count:,} comedores ({percentage:.1f}%)"
    
    # Agregar insights adicionales
    if len(tipo_counts) > 0:
        tipo_mas_comun = tipo_counts.index[0]
        analysis_text += f"""

**Insights clave:**
- El tipo m√°s com√∫n es: **{tipo_mas_comun}**
- Representa el {tipo_percentages.iloc[0]:.1f}% del total de comedores
"""
        
        if len(tipo_counts) > 1:
            segundo_tipo = tipo_counts.index[1]
            analysis_text += f"\n- El segundo tipo m√°s com√∫n es: **{segundo_tipo}** ({tipo_percentages.iloc[1]:.1f}%)"
        
        # Agregar an√°lisis de diversidad
        if len(tipo_counts) > 2:
            analysis_text += f"\n- Los 3 tipos principales representan el {tipo_percentages.iloc[:3].sum():.1f}% del total"
    
    return tipo_counts, analysis_text

def analyze_geographic_distribution(df):
    """
    Analiza la distribuci√≥n geogr√°fica de los comedores
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos de comedores
    
    Returns:
        dict: An√°lisis geogr√°fico por comuna, barrio, nodo y nicho
    """
    if df is None or df.empty:
        return None
    
    analysis = {}
    
    # An√°lisis por Comuna
    if 'COMUNA' in df.columns:
        comuna_counts = df['COMUNA'].dropna().value_counts()
        analysis['comunas'] = {
            'counts': comuna_counts,
            'total': len(comuna_counts),
            'mas_comedores': comuna_counts.index[0] if len(comuna_counts) > 0 else None,
            'max_count': comuna_counts.iloc[0] if len(comuna_counts) > 0 else 0
        }
    
    # An√°lisis por Barrio
    if 'BARRIO' in df.columns:
        barrio_counts = df['BARRIO'].dropna().value_counts()
        analysis['barrios'] = {
            'counts': barrio_counts,
            'total': len(barrio_counts),
            'mas_comedores': barrio_counts.index[0] if len(barrio_counts) > 0 else None,
            'max_count': barrio_counts.iloc[0] if len(barrio_counts) > 0 else 0
        }
    
    # An√°lisis por Nodo
    if 'NODO ' in df.columns:
        nodo_counts = df['NODO '].dropna().value_counts()
        analysis['nodos'] = {
            'counts': nodo_counts,
            'total': len(nodo_counts),
            'mas_comedores': nodo_counts.index[0] if len(nodo_counts) > 0 else None,
            'max_count': nodo_counts.iloc[0] if len(nodo_counts) > 0 else 0
        }
    
    # An√°lisis por Nicho
    if 'NICHO ' in df.columns:
        nicho_counts = df['NICHO '].dropna().value_counts()
        analysis['nichos'] = {
            'counts': nicho_counts,
            'total': len(nicho_counts),
            'mas_comedores': nicho_counts.index[0] if len(nicho_counts) > 0 else None,
            'max_count': nicho_counts.iloc[0] if len(nicho_counts) > 0 else 0
        }
    
    return analysis

def analyze_temporal_trends(df):
    """
    Analiza las tendencias temporales de vinculaci√≥n de comedores
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos de comedores
    
    Returns:
        dict: An√°lisis temporal
    """
    if df is None or df.empty:
        return None
    
    if 'A√ëO DE VINCULACI√ìN AL PROGRAMA' not in df.columns:
        return None
    
    # Limpiar y convertir a√±os
    a√±os_serie = pd.to_numeric(df['A√ëO DE VINCULACI√ìN AL PROGRAMA'], errors='coerce').dropna()
    
    if a√±os_serie.empty:
        return None
    
    a√±os_counts = a√±os_serie.value_counts().sort_index()
    
    analysis = {
        'a√±os_counts': a√±os_counts,
        'a√±o_inicio': int(a√±os_serie.min()),
        'a√±o_fin': int(a√±os_serie.max()),
        'per√≠odo_activo': int(a√±os_serie.max() - a√±os_serie.min() + 1),
        'a√±o_m√°s_activo': int(a√±os_counts.idxmax()),
        'comedores_a√±o_m√°s_activo': int(a√±os_counts.max()),
        'promedio_anual': a√±os_counts.mean(),
        'tendencia': 'creciente' if a√±os_counts.iloc[-1] > a√±os_counts.iloc[0] else 'decreciente'
    }
    
    return analysis

def analyze_population_focus(df):
    """
    Analiza el enfoque poblacional de los comedores
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos de comedores
    
    Returns:
        dict: An√°lisis de enfoques poblacionales
    """
    if df is None or df.empty:
        return None
    
    analysis = {}
    
    # Analizar enfoques diferenciales/√©tnicos
    if 'ENFOQUES DIFERENCIALES/ETNICOS\r\n(Seg√∫n su apreciaci√≥n, indique cual es el tipo de poblaci√≥n que es su mayor√≠a se atiende en el comedor)' in df.columns:
        col_name = 'ENFOQUES DIFERENCIALES/ETNICOS\r\n(Seg√∫n su apreciaci√≥n, indique cual es el tipo de poblaci√≥n que es su mayor√≠a se atiende en el comedor)'
        enfoques_data = df[col_name].dropna()
        
        # Separar m√∫ltiples opciones y contar
        all_enfoques = []
        for entry in enfoques_data:
            if pd.isna(entry) or entry == '':
                continue
            # Dividir por comas y limpiar
            enfoques = [e.strip() for e in str(entry).split(',')]
            all_enfoques.extend(enfoques)
        
        enfoques_counts = pd.Series(all_enfoques).value_counts()
        analysis['enfoques_diferenciales'] = {
            'counts': enfoques_counts,
            'total_menciones': len(all_enfoques),
            'comedores_con_enfoque': len(enfoques_data),
            'mas_comun': enfoques_counts.index[0] if len(enfoques_counts) > 0 else None
        }
    
    # Analizar etapas vitales
    if 'ETAPA VITAL \r\n(Seg√∫n su apreciaci√≥n, indique cual es el tipo de poblaci√≥n que es su mayor√≠a se atiende en el comedor)' in df.columns:
        col_name = 'ETAPA VITAL \r\n(Seg√∫n su apreciaci√≥n, indique cual es el tipo de poblaci√≥n que es su mayor√≠a se atiende en el comedor)'
        etapas_data = df[col_name].dropna()
        
        all_etapas = []
        for entry in etapas_data:
            if pd.isna(entry) or entry == '':
                continue
            etapas = [e.strip() for e in str(entry).split(',')]
            all_etapas.extend(etapas)
        
        etapas_counts = pd.Series(all_etapas).value_counts()
        analysis['etapas_vitales'] = {
            'counts': etapas_counts,
            'total_menciones': len(all_etapas),
            'comedores_con_etapa': len(etapas_data),
            'mas_comun': etapas_counts.index[0] if len(etapas_counts) > 0 else None
        }
    
    return analysis

def analyze_needs_and_problems(df):
    """
    Analiza las necesidades y problem√°ticas identificadas
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos de comedores
    
    Returns:
        dict: An√°lisis de necesidades y problem√°ticas
    """
    if df is None or df.empty:
        return None
    
    analysis = {}
    
    # Analizar necesidades
    if 'NECESIDADES' in df.columns:
        necesidades_data = df['NECESIDADES'].dropna()
        
        all_necesidades = []
        for entry in necesidades_data:
            if pd.isna(entry) or entry == '':
                continue
            necesidades = [n.strip() for n in str(entry).split(',')]
            all_necesidades.extend(necesidades)
        
        necesidades_counts = pd.Series(all_necesidades).value_counts()
        analysis['necesidades'] = {
            'counts': necesidades_counts,
            'total_menciones': len(all_necesidades),
            'comedores_con_necesidades': len(necesidades_data),
            'mas_comun': necesidades_counts.index[0] if len(necesidades_counts) > 0 else None
        }
    
    # Analizar problem√°ticas
    if 'PROBLEM√ÅTICAS' in df.columns:
        problematicas_data = df['PROBLEM√ÅTICAS'].dropna()
        
        all_problematicas = []
        for entry in problematicas_data:
            if pd.isna(entry) or entry == '':
                continue
            problematicas = [p.strip() for p in str(entry).split(',')]
            all_problematicas.extend(problematicas)
        
        problematicas_counts = pd.Series(all_problematicas).value_counts()
        analysis['problematicas'] = {
            'counts': problematicas_counts,
            'total_menciones': len(all_problematicas),
            'comedores_con_problematicas': len(problematicas_data),
            'mas_comun': problematicas_counts.index[0] if len(problematicas_counts) > 0 else None
        }
    
    return analysis

def generate_summary_stats(df):
    """
    Genera estad√≠sticas resumen del dataset
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos de comedores
    
    Returns:
        dict: Estad√≠sticas resumen
    """
    if df is None or df.empty:
        return None
    
    stats = {
        'total_records': len(df),
        'total_columns': len(df.columns),
        'missing_data': df.isnull().sum().to_dict(),
        'data_types': df.dtypes.to_dict(),
        'memory_usage': df.memory_usage(deep=True).sum(),
        'numeric_columns': df.select_dtypes(include=[np.number]).columns.tolist(),
        'text_columns': df.select_dtypes(include=['object']).columns.tolist(),
        'unique_values': {col: df[col].nunique() for col in df.columns},
        'completeness': {col: (df[col].notna().sum() / len(df)) * 100 for col in df.columns}
    }
    
    return stats

def validate_data_quality(df):
    """
    Valida la calidad de los datos
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos de comedores
    
    Returns:
        dict: Reporte de calidad de datos
    """
    if df is None or df.empty:
        return None
    
    quality_report = {
        'total_records': len(df),
        'issues': [],
        'warnings': [],
        'recommendations': []
    }
    
    # Verificar columnas cr√≠ticas
    critical_columns = [
        'TIPO DE COMEDOR',
        'NOMBRE DEL COMEDOR',
        'BARRIO',
        'COMUNA'
    ]
    
    for col in critical_columns:
        if col in df.columns:
            missing_count = df[col].isnull().sum()
            missing_percentage = (missing_count / len(df)) * 100
            
            if missing_percentage > 50:
                quality_report['issues'].append(
                    f"Columna cr√≠tica '{col}' tiene {missing_percentage:.1f}% de datos faltantes"
                )
            elif missing_percentage > 20:
                quality_report['warnings'].append(
                    f"Columna '{col}' tiene {missing_percentage:.1f}% de datos faltantes"
                )
        else:
            quality_report['issues'].append(f"Columna cr√≠tica '{col}' no encontrada")
    
    # Verificar duplicados por nombre de comedor
    if 'NOMBRE DEL COMEDOR' in df.columns:
        duplicates = df['NOMBRE DEL COMEDOR'].duplicated().sum()
        if duplicates > 0:
            quality_report['warnings'].append(
                f"Se encontraron {duplicates} nombres de comedores duplicados"
            )
    
    # Verificar consistencia en datos num√©ricos
    numeric_cols = ['COMUNA', 'NODO ', 'NICHO ', 'A√ëO DE VINCULACI√ìN AL PROGRAMA']
    for col in numeric_cols:
        if col in df.columns:
            # Intentar convertir a num√©rico y verificar errores
            numeric_series = pd.to_numeric(df[col], errors='coerce')
            conversion_errors = numeric_series.isnull().sum() - df[col].isnull().sum()
            
            if conversion_errors > 0:
                quality_report['warnings'].append(
                    f"Columna '{col}': {conversion_errors} valores no pueden convertirse a n√∫mero"
                )
    
    # Generar recomendaciones
    if len(quality_report['issues']) == 0 and len(quality_report['warnings']) == 0:
        quality_report['recommendations'].append("Los datos est√°n en buen estado general")
    else:
        if len(quality_report['issues']) > 0:
            quality_report['recommendations'].append("Revisar y corregir los problemas cr√≠ticos identificados")
        
        if len(quality_report['warnings']) > 0:
            quality_report['recommendations'].append("Considerar limpiar los datos seg√∫n las advertencias")
    
    return quality_report

def filter_dataframe(df, filters):
    """
    Aplica filtros al DataFrame
    
    Args:
        df (pandas.DataFrame): DataFrame original
        filters (dict): Diccionario con filtros a aplicar
    
    Returns:
        pandas.DataFrame: DataFrame filtrado
    """
    if df is None or df.empty:
        return df
    
    df_filtered = df.copy()
    
    for column, value in filters.items():
        if column in df_filtered.columns and value and value != 'Todos' and value != 'Todas':
            if df_filtered[column].dtype == 'object':
                df_filtered = df_filtered[df_filtered[column] == value]
            else:
                df_filtered = df_filtered[df_filtered[column].astype(str) == str(value)]
    
    return df_filtered

def export_analysis_report(df, output_format='markdown'):
    """
    Exporta un reporte completo de an√°lisis
    
    Args:
        df (pandas.DataFrame): DataFrame con los datos
        output_format (str): Formato de salida ('markdown', 'html', 'json')
    
    Returns:
        str: Reporte formateado
    """
    if df is None or df.empty:
        return "No hay datos para generar el reporte"
    
    # Ejecutar todos los an√°lisis
    tipo_analysis = analyze_tipo_comedor(df)
    geo_analysis = analyze_geographic_distribution(df)
    temporal_analysis = analyze_temporal_trends(df)
    population_analysis = analyze_population_focus(df)
    needs_analysis = analyze_needs_and_problems(df)
    summary_stats = generate_summary_stats(df)
    quality_report = validate_data_quality(df)
    
    if output_format == 'markdown':
        report = "# Reporte de An√°lisis de Comedores Comunitarios\n\n"
        
        # Resumen ejecutivo
        report += "## Resumen Ejecutivo\n\n"
        report += f"- **Total de comedores:** {len(df):,}\n"
        report += f"- **Columnas de datos:** {len(df.columns)}\n"
        
        if tipo_analysis[0] is not None:
            report += f"- **Tipos de comedores:** {len(tipo_analysis[0])}\n"
        
        if geo_analysis and 'comunas' in geo_analysis:
            report += f"- **Comunas cubiertas:** {geo_analysis['comunas']['total']}\n"
        
        # An√°lisis de tipos
        if tipo_analysis[1]:
            report += "\n" + tipo_analysis[1] + "\n"
        
        # An√°lisis geogr√°fico
        if geo_analysis:
            report += "\n## Distribuci√≥n Geogr√°fica\n\n"
            for geo_type, data in geo_analysis.items():
                if 'mas_comedores' in data and data['mas_comedores']:
                    report += f"- **{geo_type.title()}:** {data['mas_comedores']} ({data['max_count']} comedores)\n"
        
        return report
    
    elif output_format == 'json':
        import json
        report_data = {
            'summary': summary_stats,
            'quality': quality_report,
            'tipo_analysis': {
                'counts': tipo_analysis[0].to_dict() if tipo_analysis[0] is not None else None,
                'analysis': tipo_analysis[1]
            },
            'geographic': geo_analysis,
            'temporal': temporal_analysis,
            'population': population_analysis,
            'needs': needs_analysis
        }
        return json.dumps(report_data, indent=2, default=str)
    
    else:
        return "Formato no soportado"